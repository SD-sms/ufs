#!/usr/bin/env bash

#
#-----------------------------------------------------------------------
#
# The J-Job script for getting the model files that will be used for
# either initial conditions or lateral boundary conditions for the
# experiment.
#
#-----------------------------------------------------------------------
#
date
export PS4='+ $SECONDS + '
set -xue
#
#-----------------------------------------------------------------------
#
# Set the NCO standard environment variables (Table 1, pp.4)
#
#-----------------------------------------------------------------------
#
export USHsrw="${HOMEdir}/ush"
export EXECsrw="${HOMEdir}/exec"
export FIXsrw="${HOMEdir}/fix"
export PARMsrw="${HOMEdir}/parm"
export SCRIPTSsrw="${HOMEdir}/scripts"
#
#-----------------------------------------------------------------------
#
# Source the variable definitions file and the bash utility functions.
#
#-----------------------------------------------------------------------
#
. ${PARMsrw}/source_util_funcs.sh
task_global_vars=( "MACHINE" "WORKFLOW_MANAGER" "SCHED" "NET_default" \
  "RUN_default" "DO_ENSEMBLE" "EXTRN_MDL_ICS_OFFSET_HRS" \
  "EXTRN_MDL_NAME_ICS" "FV3GFS_FILE_FMT_ICS" "EXTRN_MDL_LBCS_OFFSET_HRS" \
  "EXTRN_MDL_NAME_LBCS" "FV3GFS_FILE_FMT_LBCS" )
for var in ${task_global_vars[@]}; do
  source_config_for_task ${var} ${GLOBAL_VAR_DEFNS_FP}
done
#
#-----------------------------------------------------------------------
#
# Get the full path to the file in which this script/function is located
# (scrfunc_fp), the name of that file (scrfunc_fn), and the directory in
# which the file is located (scrfunc_dir).
#
#-----------------------------------------------------------------------
#
scrfunc_fp=$( $READLINK -f "${BASH_SOURCE[0]}" )
scrfunc_fn=$( basename "${scrfunc_fp}" )
scrfunc_dir=$( dirname "${scrfunc_fp}" )
#
#-----------------------------------------------------------------------
#
# Print message indicating entry into script.
#
#-----------------------------------------------------------------------
#
print_info_msg "
========================================================================
Entering script:  \"${scrfunc_fn}\"
In directory:     \"${scrfunc_dir}\"

This is the J-job script for the task that copies or fetches external
model files from disk, HPSS, or URL, and stages them for downstream use
to generate initial or lateral boundary conditions for the FV3 model.
========================================================================"
#
#-----------------------------------------------------------------------
#
# Define job and jobid by default for rocoto
#
#-----------------------------------------------------------------------
#
WORKFLOW_MANAGER="${WORKFLOW_MANAGER:-rocoto}"
if [ "${WORKFLOW_MANAGER}" = "rocoto" ]; then
  if [ "${SCHED}" = "slurm" ]; then
    job=${SLURM_JOB_NAME}
    pid=${SLURM_JOB_ID}
  elif [ "${SCHED}" = "pbspro" ]; then
    job=${PBS_JOBNAME}
    pid=${PBS_JOBID}
  else
    job="task"
    pid=$$
  fi
  jobid="${job}.${PDY}${cyc}.${pid}"
fi
#
#-----------------------------------------------------------------------
#
# Create a temp working directory (DATA) and cd into it.
#
#-----------------------------------------------------------------------
#
export DATA="${DATA:-${DATAROOT}/${jobid}}"
mkdir -p $DATA
cd $DATA
#
#-----------------------------------------------------------------------
#
# Define NCO environment variables and set COM type definitions.
#
#-----------------------------------------------------------------------
#
export NET="${NET:-${NET_default}}"
export RUN="${RUN:-${RUN_default}}"

[[ "$WORKFLOW_MANAGER" = "rocoto" ]] && export COMROOT=$COMROOT
if [ "${MACHINE}" = "WCOSS2" ]; then
  export COMIN="${COMIN:-$(compath.py -o ${NET}/${model_ver}/${RUN}.${PDY}/${cyc}${SLASH_ENSMEM_SUBDIR})}"
  export COMOUT="${COMOUT:-$(compath.py -o ${NET}/${model_ver}/${RUN}.${PDY}/${cyc}${SLASH_ENSMEM_SUBDIR})}"
else
  export COMIN="${COMIN:-${COMROOT}/${NET}/${model_ver}}"
  export COMOUT="${COMOUT:-${COMROOT}/${NET}/${model_ver}/${RUN}.${PDY}/${cyc}${SLASH_ENSMEM_SUBDIR}}"
fi

mkdir -p ${COMOUT}

# Create a teomporary share directory
if [ "${ICS_OR_LBCS}" = "ICS" ]; then
  export DATA_SHARE="${DATA_SHARE:-${DATAROOT}/DATA_SHARE/${PDY}${cyc}/ICS}"
elif [ "${ICS_OR_LBCS}" = "LBCS" ]; then
  export DATA_SHARE="${DATA_SHARE:-${DATAROOT}/DATA_SHARE/${PDY}${cyc}/LBCS}"
fi

mkdir -p ${DATA_SHARE}

# Run setpdy to initialize PDYm and PDYp variables
export cycle="${cycle:-t${cyc}z}"
setpdy.sh
. ./PDY
#
#-----------------------------------------------------------------------
#
# Set sub-cycle and ensemble member names in file/diectory names
#
#-----------------------------------------------------------------------
#
if [ ${subcyc} -ne 0 ]; then
  export cycle="t${cyc}${subcyc}z"
fi
if [ $(boolify "${DO_ENSEMBLE}") = "TRUE" ] && [ ! -z ${ENSMEM_INDX} ]; then
  export dot_ensmem=".mem${ENSMEM_INDX}"
else
  export dot_ensmem=
fi
#
#-----------------------------------------------------------------------
#
# Check whether the environment variable ICS_OR_LBCS is set to a valid
# value.  This variable specifies whether we are getting the external
# model files for the purpose of generating initial conditions (ICs) or
# lateral boundary condtions (LBCs) for the forecast model.
#
#-----------------------------------------------------------------------
#
valid_vals_ICS_OR_LBCS=( "ICS" "LBCS" )
check_var_valid_value "ICS_OR_LBCS" "valid_vals_ICS_OR_LBCS"
#
#-----------------------------------------------------------------------
#
# Set parameters for grabbing either the initial conditions from analysis or
# forecast files of external models, or the lateral boundary conditions
# from external models. This script has been called to do the work for
# one or the other.
#
#-----------------------------------------------------------------------
#
if [ "${ICS_OR_LBCS}" = "ICS" ]; then
  export TIME_OFFSET_HRS=${EXTRN_MDL_ICS_OFFSET_HRS:-0}
  export EXTRN_MDL_NAME=${EXTRN_MDL_NAME_ICS}
  GFS_FILE_FMT=${FV3GFS_FILE_FMT_ICS}
elif [ "${ICS_OR_LBCS}" = "LBCS" ]; then
  export TIME_OFFSET_HRS=${EXTRN_MDL_LBCS_OFFSET_HRS:-0}
  export EXTRN_MDL_NAME=${EXTRN_MDL_NAME_LBCS}
  GFS_FILE_FMT=${FV3GFS_FILE_FMT_LBCS}
fi
#
#-----------------------------------------------------------------------
#
# Set the external model start time
#
#-----------------------------------------------------------------------
#
yyyymmdd=${PDY}
hh=${cyc}
export EXTRN_MDL_CDATE=$( $DATE_UTIL --utc --date "${yyyymmdd} ${hh} UTC - ${TIME_OFFSET_HRS} hours" "+%Y%m%d%H" )
#
#-----------------------------------------------------------------------
#
# Check whether output files from the specified external model
# (EXTRN_MDL_NAME) are available on the specified cycle date and time
# (EXTRN_MDL_CDATE).
#
#-----------------------------------------------------------------------
#
function data_unavailable() {

  local name cdate end_date min_max

  name=$1
  cdate=$2
  end_date=$3
  min_max=$4

  if [ ${min_max} = max ]; then
    msg="\
Output from the specified external model (EXTRN_MDL_NAME) is not availa-
ble for the specified cycle date and time (EXTRN_MDL_CDATE) because the latter is
later than the last forecast date and time (cdate_max) with this model:
  EXTRN_MDL_NAME = \"${name}\"
  CDATE_max = \"${end_date}\"
  EXTRN_MDL_CDATE = \"${cdate}\""

  elif [ ${min_max} = min ]; then
    msg="\
Output from the specified external model (EXTRN_MDL_NAME) is not availa-
ble for the specified cycle date and time (EXTRN_MDL_CDATE) because the latter is
earlier than the implementation date of this model:
  EXTRN_MDL_NAME = \"${name}\"
  CDATE_min = \"${end_date}\"
  EXTRN_MDL_CDATE = \"${cdate}\""
  fi

  echo ${msg}
}


case ${EXTRN_MDL_NAME} in

"GSMGFS")
# The transition date from the GSMGFS to the FV3GFS was 2019061212, i.e.
# this was the first official forecast with the FV3GFS.  So we set the
# last CDATE for the GSMGFS to the one 6 hours before this.
  CDATE_max="2019061206"
  if [ "$EXTRN_MDL_CDATE" -gt "$CDATE_max" ]; then
    print_err_msg_exit "\
      $(data_unavailable $EXTRN_MDL_NAME $EXTRN_MDL_CDATE $CDATE_max max)"
  fi
  ;;

"FV3GFS")
# The transition date from the GSMGFS to the FV3GFS was 2019061212, i.e.
# this was the first official forecast with the FV3GFS.  However, paral-
# lel runs with the FV3GFS go back to 2018121500.  So we set the first 
# EXTRN_MDL_CDATE for the FV3GFS to this date and time.
  CDATE_min="2018121500"
  CDATE_min_netcdf="2021032100"
  CDATE_max_nemsio="2021032018"
  if [ "$EXTRN_MDL_CDATE" -lt "$CDATE_min" ]; then
    print_err_msg_exit "\
      $(data_unavailable $EXTRN_MDL_NAME $EXTRN_MDL_CDATE $CDATE_min min)"
  elif [ "${GFS_FILE_FMT}" = "netcdf" ] && [ "${EXTRN_MDL_CDATE}" -lt "${CDATE_min_netcdf}" ]; then
    print_err_msg_exit "\
      NETCDF is not available for this date:: However, NEMSIO is available:: \
      $(data_unavailable $EXTRN_MDL_NAME $EXTRN_MDL_CDATE $CDATE_min_netcdf min)"
  elif [ "${GFS_FILE_FMT}" = "nemsio" ] && [ "${EXTRN_MDL_CDATE}" -gt "${CDATE_max_nemsio}" ]; then
    print_err_msg_exit "\
      NEMSIO is not available for this date:: However, NETCDF is available::  \
      $(data_unavailable $EXTRN_MDL_NAME $EXTRN_MDL_CDATE $CDATE_max_nemsio max)"
  fi
  ;;

"RAP")
# Examination of the HPSS archives shows that the RAPX data goes back to
# July 01, 2015.
  CDATE_min="2015070100"
  if [ "$EXTRN_MDL_CDATE" -lt "$CDATE_min" ]; then
    print_err_msg_exit "\
      $(data_unavailable $EXTRN_MDL_NAME $EXTRN_MDL_CDATE $CDATE_min min)"
  fi
  ;;

"HRRR")
# From the HRRR home page (https://rapidrefresh.noaa.gov/hrrr), the 
# implementation of the first version of the operational HRRR was 
# September 30, 2014.
  CDATE_min="2014103000"
  if [ "$EXTRN_MDL_CDATE" -lt "$CDATE_min" ]; then
    print_err_msg_exit "\
      $(data_unavailable $EXTRN_MDL_NAME $EXTRN_MDL_CDATE $CDATE_min min)"
  fi
  ;;

esac
#
#-----------------------------------------------------------------------
#
# Set the directory where the external model files should be stored
#
#-----------------------------------------------------------------------
#
export EXTRN_MDL_STAGING_DIR="${EXTRN_MDL_STAGING_DIR:-${DATA_SHARE}}"
#
#-----------------------------------------------------------------------
#
# Call the ex-script for this J-job and pass to it the necessary variables.
#
#-----------------------------------------------------------------------
#
export pgmout="${DATA}/OUTPUT.$$"
env

${SCRIPTSsrw}/exsrw_get_extrn_mdl_files.sh
export err=$?; err_chk

if [ -e "$pgmout" ]; then
  cat $pgmout
fi
#
#-----------------------------------------------------------------------
#
# Whether or not working directory DATA should be kept.
#
#-----------------------------------------------------------------------
#
if [ "${KEEPDATA}" = "NO" ]; then
  rm -rf ${DATA}
fi
date

